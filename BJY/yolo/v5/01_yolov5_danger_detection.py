import sys, time
import numpy as np
import torch
import cv2
# from ultralytics import YOLO
from collections import deque   # ê³ ì •ê¸¸ì´ í


def euclidean_dist(x1, y1, x2, y2):
    return ((x1-x2)**2 + (y1-y2)**2)**0.5

# ğŸ˜
def get_first_last_values(forklift_deque):
    """
    dequeì—ì„œ None ê°’ì„ ì œì™¸í•œ ê°’ë“¤ ì¤‘ì—ì„œ ê°€ì¥ ì²« ê°’ê³¼ ë§ˆì§€ë§‰ ê°’ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜
    - forklift_deque : ì§€ê²Œì°¨ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œí‘œê°’ì´ ì €ì¥ëœ deque ê°ì²´
    """
    # deque ë‚´ì˜ ê°’ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš° ì¢…ë£Œ
    deque_len = len(forklift_deque)
    if deque_len <= 1:
        return
    
    front, back = 0, -1
    while True:
        value1 = forklift_deque[front]
        if value1 != None:
            break
        else:
            front += 1
    
    while True:
        value2 = forklift_deque[back]
        if value2 != None:
            break
        else:
            back -= 1
    
    # value1, value2 ê°€ ë™ì¼í•  ê²½ìš°(deque ë‚´ì—ì„œ Noneì´ ì•„ë‹Œ ê°’ì´ ë‹¨ í•œ ê°œ) None ë°˜í™˜
    if front == back + deque_len:
        return
    
    return value1, value2


def extend_line(height, width, x1, y1, x2, y2):
    """
    forklift ì˜ ìµœê·¼ nê°œ í”„ë ˆì„ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ì§„í–‰ ë°©í–¥ì„ êµ¬í•˜ê³ , ì‚¬ì§„ ìƒì—ì„œì˜ ì–‘ ëì ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜
    nê°œ í”„ë ˆì„ ì •ë³´ê°€ ì €ì¥ëœ deque ë‚´ì˜ ê°€ì¥ ì²« ê°’ê³¼ ë ê°’ì„ ì‚¬ìš©í•´ì„œ ë‘ ì ì„ ì‡ëŠ” ì§ì„ ì˜ ì–‘ ë ì ì„ êµ¬í•˜ì—¬ ë°˜í™˜í•œë‹¤.
    - height, width : ëŒ€ìƒ ì´ë¯¸ì§€ì˜ ë†’ì´, ë„ˆë¹„
    - x1, y1, x2, y2 : ì§ì„ ì„ ê·¸ë¦´ ë•Œ ì‚¬ìš©í•  ë‘ ì ì˜ x, y ê°’
    """
    
    dx = x2 - x1
    dy = y2 - y1
    
    if dx == 0: # ì„¸ë¡œì„ 
        return (int(x1), 0), (int(x1), height)
    elif dy == 0:   # ê°€ë¡œì„ 
        return (0, int(y1)), (width, int(y1))
    else:
        grad = dy / dx
        points = []
        
        # left border (x=0)
        y = y1 - x1 * grad
        if 0 <= y <= height:
            points.append((0, int(y)))
        
        # Right border (x=width)
        y = y1 + (width - x1) * grad
        if 0 <= y <= height:
            points.append((width, int(y)))
        
        # Top border (y=0)
        x = x1 - y1 / grad
        if 0 <= x <= width:
            points.append((int(x), 0))
        
        # Bottom border (y=height)
        x = x1 + (height - y1) / grad
        if 0 <= x <= width:
            points.append((int(x), height))
        
        if len(points) == 2:
            return points[0], points[1]

# ğŸ˜
def calculate_route_coefs(x1, y1, x2, y2):
    """
    forklift ì˜ ìµœê·¼ nê°œ í”„ë ˆì„ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ì§„í–‰ ë°©í–¥ì˜ ìŒí•¨ìˆ˜ ê³„ìˆ˜ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜
    (x1, y1), (x2, y2) ê°’ì„ ë°›ì•„ì„œ ë‘ ì ì„ ì‡ëŠ” ì§ì„ ì„ êµ¬í•œë‹¤. (ìŒí•¨ìˆ˜ ì‹ ax+by+c=0)
    """
    dx = x2 - x1
    dy = y2 - y1
    grad = dy / dx
    
    # ìŒí•¨ìˆ˜ ì‹ ax+by+c=0
    if dx == 0:
        a, b, c = 1, 0, -x1
    elif dy == 0:
        a, b, c = 0, 1, -y1
    else:
        a = grad
        b, c = -1, y1 - (a * x1)
    
    return a, b, c

# ğŸ˜
def detect_danger_between_forklift_and_person(forklift_deque, person_bbox):
    """ [ì—¬ëŸ¬ ì‚¬ëŒì„ ëŒ€ìƒìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì • í•„ìš”]
    forkliftì˜ ì˜ˆìƒ ì§„í–‰ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ê³ , ì–´ë–¤ í•œ ì‚¬ëŒì´ ê·¸ ê²½ë¡œë¡œë¶€í„° ì¶©ë¶„íˆ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    - ì§€ê²Œì°¨ì˜ ì¢…ë¥˜ : (V), (D), (H)
    - forklift_deque : forkliftì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì—¬ëŸ¬ ê°œë¥¼ ì €ì¥í•˜ëŠ” deque ê°ì²´
    - person_bbox : personì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ê°ì²´
    """
    
    # dequeì—ì„œ ë‘ í”„ë ˆì„ì˜ ì¢Œí‘œê°’ ì¶”ì¶œ
    values = get_first_last_values(forklift_deque)
    if not values:
        return False
    else:
        value1, value2 = values
    x1, y1, w1, h1, _, cls1 = value1  # (xywh, conf, cls)
    x2, y2, w2, h2, _, cls2 = value2
    
    # x1, y1, _, _ = forklift_deque[0]
    # x2, y2, _, _ = forklift_deque[-1]
    
    coefs = calculate_route_coefs(x1, y1, x2, y2)
    a, b, c = coefs
    
    p_x1, p_y1, p_w1, p_h1 = person_bbox
    dist = abs(a * p_x1 + b * p_y1 + c) / (a**2 + b**2)**0.5

    # forklift_len = (w2**2 + h2**2)**0.5
    # person_len = (w1**2 + h2**2)**0.5
    
    tan_value = abs(a)  # ì§€ê²Œì°¨ ì§„í–‰ë°©í–¥ê³¼ xì¶•ì´ ì´ë£¨ëŠ” ì˜ˆê°ì‚¼ê°í˜•ì˜ tangent ê°’
    cos_value = 1 / (1 + tan_value**2)**0.5
    sin_value = tan_value / (1 + tan_value**2)**0.5
    
    forklift_len = w2 * sin_value + h2 * cos_value      # ì§€ê²Œì°¨ì˜ ì§„í–‰ë°©í–¥ê³¼ ìˆ˜ì§ì¸ ì§ì„ ì— ì§€ê²Œì°¨ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì •ì‚¬ì˜í•œ ê¸¸ì´
    person_len = p_w1 * sin_value + p_h1 * cos_value    # ì§€ê²Œì°¨ì˜ ì§„í–‰ë°©í–¥ê³¼ ìˆ˜ì§ì¸ ì§ì„ ì— ì‚¬ëŒì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì •ì‚¬ì˜í•œ ê¸¸ì´
    
    ### ì§€ê²Œì°¨ì˜ ë°©í–¥ì— ë”°ë¼ forklift_lenì˜ ê¸¸ì´ì— ê°€ì¤‘ì¹˜ ì ìš© (ì¼ë°˜ì ìœ¼ë¡œ Hì¼ ë•Œ ë³´ë‹¤ V, Dì¼ ë•Œ ë” í¬ê²Œ ì¡íˆê¸° ë•Œë¬¸)
    weight_type = {1: 0.85, 3: 0.85, 4: 1.0}  # (V), (H) => 0.8 ~ 0.9
    weight = weight_type[int(cls2)]
    forklift_len = forklift_len * weight
    
    danger_cond1 = True if (forklift_len + person_len) * 0.5 >= dist else False
    
    ### ì‚¬ëŒìœ¼ë¡œë¶€í„° ê°€ê¹Œì›Œì§€ëŠ”ì§€ ì²´í¬í•˜ëŠ” ì½”ë“œ
    dist1 = euclidean_dist(x1, y1, p_x1, p_y1)
    dist2 = euclidean_dist(x2, y2, p_x1, p_y1)
    danger_cond2 = True if (dist1 > dist2) else False
    
    # danger_flag
    return danger_cond1 & danger_cond2

## --------------------------------------------------------------------------------------
## ë©”ì¸ ì½”ë“œ
## --------------------------------------------------------------------------------------

# ì»¤ìŠ¤í…€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = torch.hub.load('./yolov5', 'custom', path='./model/mnv_Model.pt', source='local') # â­

# ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
video_file = "./safe2.mp4"
cap = cv2.VideoCapture(video_file)

# ë¹„ë””ì˜¤ ê°ì²´ê°€ ì—´ë ¸ëŠ”ì§€ í™•ì¸
if not cap.isOpened():
    print("Video open failed!")
    sys.exit()

# ìµœê·¼ nê°œ í”„ë ˆì„ì„ ì €ì¥í•  ë°í¬(deque) ê°ì²´ ìƒì„±
DEQUE_MAXLEN = 5
forklift_frames = deque(maxlen=DEQUE_MAXLEN)
person_frames = deque(maxlen=DEQUE_MAXLEN)

# í”„ë ˆì„ ê°„ê²© ì„¤ì • (ê°€ë³€ì )
frame_interval = 4

# forklift, person valid flag
forklift_valid, forklift_moves, person_valid = False, False, False # ì´ˆê¸°ê°’ : False

# ì§€ê²Œì°¨ ì›€ì§ì„ì˜ ê¸°ì¤€ì¹˜
MOVE_OR_NOT = 7

# ì§€ê²Œì°¨ w(ë„ˆë¹„), h(ë†’ì´) ìµœëŒ€ê°’
# forklift_maxlen = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]  # (V), (D), (H) ğŸ˜ í…ŒìŠ¤íŠ¸ìš©

# 1í”„ë ˆì„ì”© ì½ìœ¼ë©° ìœ„í—˜ìƒí™© ì²˜ë¦¬
while True:
    # time.sleep(0.2) # ğŸ˜ í…ŒìŠ¤íŠ¸ìš©
    
    # ë§ˆì§€ë§‰ì— ì ìš©í•  cv2 ì‚¬í•­ë“¤
    cv2_list = []
    
    # ë¹„ë””ì˜¤ì—ì„œ í˜„ì¬ í”„ë ˆì„ì˜ ìœ„ì¹˜
    current_frame_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
    
    # ì¹´ë©”ë¼ì˜ ret, frame ê°’ ê°€ì ¸ì˜¤ê¸°
    # - ret : boolean (success or not)
    # - frame : image array vector
    ret, frame = cap.read()
    
    if not ret: 
        break
    
    if current_frame_pos % frame_interval == 0:
        # [1] YOLOv8 ëª¨ë¸ ì ìš©
        # results : models.common.Detections
        print('[1] ì‹¤í–‰')
        torch_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # â­ (<= YOLOv5 í•µì‹¬ ì½”ë“œë“¤)
        results = model(torch_frame)  # â­
        
        # Visualize the results on the frame
        annotated_frames = results.render() # â­
        annotated_frame = cv2.cvtColor(annotated_frames[0], cv2.COLOR_BGR2RGB)  # â­
        
        detected_labels = results.pred[0][:, -1].int().tolist() # â­
        
        # [2] ì§€ê²Œì°¨ê°€ ìˆëŠ”ì§€ í™•ì¸ (Trolly:2ëŠ” ì œì™¸)
        if set(detected_labels) & set([1, 3, 4]):
            print('[2-1] ì‹¤í–‰')
            indices = [i for i, x in enumerate(detected_labels) if x in [1, 3, 4]]  # ğŸ˜
            forklift_frame = results.xywh[0][indices[0]].clone()  # ğŸ˜ â­
            x_, y_, w_, h_, _, cls_ = forklift_frame  # ğŸ˜
            
            # ê° ì§€ê²Œì°¨ íƒ€ì…ë³„ ìµœëŒ€ ëŒ€ê°ì„  ê¸¸ì´ ê°±ì‹ 
            # forklift_type = {1: 0, 3: 1, 4: 2}
            # idx = forklift_type[int(cls_)]
            # dist_ = euclidean_dist(0, 0, w_, h_)
            # if dist_ > forklift_maxlen[idx][2]:
            #     forklift_maxlen[idx][0] = w_
            #     forklift_maxlen[idx][1] = h_
            #     forklift_maxlen[idx][2] = dist_
            
            ### ì¤‘ì ì¢Œí‘œ ë³´ì • ì½”ë“œ (í™”ë©´ ì–‘ ëì— ìˆì„ ë•Œ)
            
            forklift_frames.append(forklift_frame)  # ğŸ˜ â­
            
            # ì§€ê²Œì°¨ê°€ ì›€ì§ì´ëŠ” ê±°ë¦¬ ê³„ì‚°, ì›€ì§ì´ëŠ”ì§€ ì—¬ë¶€ íŒŒì•…
            print(f'forklift_valid ê°’ : {forklift_valid}')
            print(f'forklift_frames ê¸¸ì´ : {len(forklift_frames)}')
            if (len(forklift_frames)==DEQUE_MAXLEN) and (forklift_frames.count(None) / len(forklift_frames) <= 0.5): # ğŸ˜ğŸ˜
                print('[2-2] ì‹¤í–‰')
                forklift_valid = True
                
                first_value, last_value = get_first_last_values(forklift_frames) # â³
                x1, y1, _, _, _, _ = first_value
                x2, y2, _, _, _, _ = last_value
                dist = euclidean_dist(x1, y1, x2, y2)   # ë³€ìœ„ ê³„ì‚°
                forklift_moves = True if dist > MOVE_OR_NOT else False  # ë³€ìœ„ê°€ ê¸°ì¤€ì¹˜ë³´ë‹¤ í¬ë©´ ì›€ì§ì¸ë‹¤ê³  íŒë‹¨
        else:
            forklift_frames.append(None)
            if (len(forklift_frames)==DEQUE_MAXLEN) and (forklift_frames.count(None) / len(forklift_frames) > 0.5): # ğŸ˜ğŸ˜
                # íŠ¸ë˜í‚¹ ì¤‘ì¸ ì§€ê²Œì°¨ê°€ ì—†ì–´ì¡Œë‹¤ë©´ ë°í¬ ì´ˆê¸°í™”
                if forklift_valid:
                    forklift_frames.clear()
                    forklift_valid = False
        
        # [3] ì‚¬ëŒì´ ìˆëŠ”ì§€ í™•ì¸ (ì§€ê²Œì°¨ê°€ ìˆê³  ì›€ì§ì¼ ë•Œ)
        if forklift_valid and forklift_moves and (0 in detected_labels):
            print('[3-1] ì‹¤í–‰')
            indices = [i for i, x in enumerate(detected_labels) if x == 0] # ğŸ˜
            person_frame = results.xywh[0][indices[0]][:-2].clone() # ğŸ˜ â­
            person_frame[1] += (person_frame[3] / 4)    # ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ ë²”ìœ„ ì¡°ì •(ë°œ ë¶€ë¶„ìœ¼ë¡œ í•œì •)
            person_frame[3] = (person_frame[3] / 2)
            person_frames.append(person_frame)
            none_count = person_frames.count(None)
            if len(person_frames)==DEQUE_MAXLEN and none_count / len(person_frames) < 0.5:
                print('[3-2] ì‹¤í–‰')
                person_valid = True
            else:
                person_valid = False
        else:
            person_valid = False
        
        # [4] ì§€ê²Œì°¨ ì˜ˆìƒ ì§„í–‰ ë£¨íŠ¸ì™€ì˜ ì§ì„  ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì„œ ìœ„í—˜ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤Œ
        if person_valid and detect_danger_between_forklift_and_person(forklift_frames, person_frame):  # â³
            print('[4] ì‹¤í–‰')
            cv2_list.append(('collision risk occurred :o', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)) # ğŸ˜
            cv2_list.append((f'{person_frame}', (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 3)) # í…ŒìŠ¤íŠ¸ìš©
            print('collision risk occurred :o') # í…ŒìŠ¤íŠ¸ìš©
            # [GUI] if not mute : self.danger() # [ìœ„í—˜ìƒí™© ë°œìƒ ì‹œê° ì €ì¥ ê¸°ëŠ¥]
        
        # [5] ì§€ê²Œì°¨ ì˜ˆìƒ ì§„í–‰ ë£¨íŠ¸(ì§ì„ ) í‘œì‹œ
        if forklift_valid and forklift_moves:
            print('[5-1] ì‹¤í–‰')
            first_value, last_value = get_first_last_values(forklift_frames) # â³
            x1, y1, _, _, _, _ = first_value
            x2, y2, _, _, _, _ = last_value
            
            # ëŒ€ìƒ ì‚¬ì§„ì˜ ë†’ì´, ë„ˆë¹„
            height, width, _ = results.ims[0].shape
            
            if forklift_moves:
                print('[5-2] ì‹¤í–‰')
                point1, point2 = extend_line(height, width, x1, y1, x2, y2) # ğŸ˜
                cv2_list.append((point1, point2, (0, 255, 0), 3)) # ğŸ˜
                dist = euclidean_dist(x1, y1, x2, y2)   # ë¹¼ë„ ë˜ë‚˜?
                cv2_list.append((f'Dist : {dist:.3f}', (1030, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)) # ğŸ˜
        
        # cv2_list.append((f'forklift(V) => {forklift_maxlen[0]}', (30, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)) # í…ŒìŠ¤íŠ¸ìš©
        # cv2_list.append((f'forklift(D) => {forklift_maxlen[1]}', (30, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)) # í…ŒìŠ¤íŠ¸ìš©
        # cv2_list.append((f'forklift(H) => {forklift_maxlen[2]}', (30, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)) # í…ŒìŠ¤íŠ¸ìš©
        
        # [6] cv2.putText, cv2.line ì¼ê´„ ì ìš©
        if len(cv2_list) > 0 :
                for k in range(0, len(cv2_list)):
                    if isinstance(cv2_list[k][0], str):
                        # í”„ë ˆì„, í…ìŠ¤íŠ¸ ë‚´ìš©, ë„£ì„ ìœ„ì¹˜, í°íŠ¸ ì¢…ë¥˜, í°íŠ¸ í¬ê¸°, í°íŠ¸ ìƒ‰, í°íŠ¸ êµµê¸°
                        cv2.putText(annotated_frame, cv2_list[k][0], cv2_list[k][1], cv2_list[k][2], cv2_list[k][3], cv2_list[k][4], cv2_list[k][5])
                    else:
                        # í”„ë ˆì„, ì¢Œí‘œ1, ì¢Œí‘œ2, ìƒ‰ìƒ, êµµê¸°
                        cv2.line(annotated_frame, cv2_list[k][0], cv2_list[k][1], cv2_list[k][2], cv2_list[k][3])
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì˜µì…˜)
        scale_factor = 0.8
        resized_frame = cv2.resize(annotated_frame, None, fx=scale_factor, fy=scale_factor)
        
        # [7] ì–´ë…¸í…Œì´ì…˜ëœ ê²°ê³¼ í”„ë ˆì„ì„ í‘œì‹œ
        cv2.imshow('RESULT IMAGE', resized_frame)
        
        print(f'forklift_deque ê°’ : {forklift_frames}')
        print(f'forklift_valid ê°’ : {forklift_valid}')
        print('='*50)
    
    # 'q'ê°€ ëˆŒë¦¬ë©´ ë£¨í”„ë¥¼ ì¤‘ë‹¨
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ë¥¼ í•´ì œí•˜ê³  í‘œì‹œ ì°½ ë‹«ê¸°
cap.release()
cv2.destroyAllWindows()
