{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a YOLOv9c model from scratch\n",
    "# model = YOLO('yolov9c.yaml')\n",
    "\n",
    "# Build a YOLOv9c model from pretrained weight\n",
    "model = YOLO('yolov9c.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9c summary: 618 layers, 25590912 parameters, 0 gradients, 104.0 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(618, 25590912, 0, 104.02268160000003)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chosen_model, img, classes=[], conf=0.5):\n",
    "    \"\"\"\n",
    "    classes : (Optional) A list of class names to filter predictions to\n",
    "    conf : (Optional) The minimum confidence threshold for a prediction to be considered\n",
    "    \"\"\"\n",
    "    if classes:\n",
    "        results = chosen_model.predict(img, classes=classes, conf=conf)\n",
    "    else:\n",
    "        results = chosen_model.predict(img, conf=conf)\n",
    "    return results  # name, conf, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_detect(chosen_model, img, classes=[], conf=0.5, rectangle_thickness=2, text_thickness=2):\n",
    "    # YOLOv9 모델으로 predict\n",
    "    results = predict(chosen_model, img, classes, conf=conf)\n",
    "    # YOLOv9 predict 결과마다 bounding box, 클래스명 표시\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cv2.rectangle(img, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 0), rectangle_thickness)\n",
    "            cv2.putText(img, f\"{result.names[int(box.cls[0])]}\",\n",
    "                        (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), text_thickness)\n",
    "    return img, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kdp\\\\PycharmProjects\\\\KDT_MNVISION\\\\BJY\\\\yolo\\\\v9'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image\n",
    "image = cv2.imread('kdt.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image(img: np.ndarray):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 이미지 출력\n",
    "# show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 7 persons, 1 handbag, 1 bottle, 1 chair, 688.6ms\n",
      "Speed: 0.0ms preprocess, 688.6ms inference, 1457.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# result_info    => <class 'list'>\n",
    "# result_info[0] => <class 'ultralytics.engine.results.Results'>\n",
    "result_img, result_info = predict_and_detect(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_info[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8963])\n",
      "data: tensor([[7.9481e-01, 6.0874e+02, 3.9835e+02, 1.0490e+03, 8.9629e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[199.5722, 828.8943, 397.5548, 440.3011]])\n",
      "xywhn: tensor([[0.1426, 0.7894, 0.2840, 0.4193]])\n",
      "xyxy: tensor([[7.9481e-01, 6.0874e+02, 3.9835e+02, 1.0490e+03]])\n",
      "xyxyn: tensor([[5.6772e-04, 5.7976e-01, 2.8454e-01, 9.9909e-01]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8659])\n",
      "data: tensor([[6.5336e+02, 7.2549e+02, 1.0133e+03, 1.0494e+03, 8.6589e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[833.3262, 887.4601, 359.9344, 323.9318]])\n",
      "xywhn: tensor([[0.5952, 0.8452, 0.2571, 0.3085]])\n",
      "xyxy: tensor([[ 653.3590,  725.4943, 1013.2934, 1049.4260]])\n",
      "xyxyn: tensor([[0.4667, 0.6909, 0.7238, 0.9995]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8647])\n",
      "data: tensor([[2.8457e+02, 6.4644e+02, 6.1625e+02, 1.0489e+03, 8.6467e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[450.4136, 847.6793, 331.6814, 402.4756]])\n",
      "xywhn: tensor([[0.3217, 0.8073, 0.2369, 0.3833]])\n",
      "xyxy: tensor([[ 284.5729,  646.4415,  616.2543, 1048.9171]])\n",
      "xyxyn: tensor([[0.2033, 0.6157, 0.4402, 0.9990]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8080])\n",
      "data: tensor([[8.7538e+02, 5.0873e+02, 1.1665e+03, 1.0468e+03, 8.0805e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1020.9453,  777.7732,  291.1210,  538.0818]])\n",
      "xywhn: tensor([[0.7292, 0.7407, 0.2079, 0.5125]])\n",
      "xyxy: tensor([[ 875.3848,  508.7323, 1166.5057, 1046.8141]])\n",
      "xyxyn: tensor([[0.6253, 0.4845, 0.8332, 0.9970]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.7876])\n",
      "data: tensor([[7.6283e+02, 5.6719e+02, 1.0170e+03, 1.0477e+03, 7.8755e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[889.9266, 807.4495, 254.1957, 480.5162]])\n",
      "xywhn: tensor([[0.6357, 0.7690, 0.1816, 0.4576]])\n",
      "xyxy: tensor([[ 762.8288,  567.1913, 1017.0245, 1047.7075]])\n",
      "xyxyn: tensor([[0.5449, 0.5402, 0.7264, 0.9978]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.7757])\n",
      "data: tensor([[525.3755, 587.5152, 614.8055, 692.1971,   0.7757,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[570.0905, 639.8562,  89.4301, 104.6819]])\n",
      "xywhn: tensor([[0.4072, 0.6094, 0.0639, 0.0997]])\n",
      "xyxy: tensor([[525.3755, 587.5152, 614.8055, 692.1971]])\n",
      "xyxyn: tensor([[0.3753, 0.5595, 0.4391, 0.6592]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([39.])\n",
      "conf: tensor([0.7715])\n",
      "data: tensor([[1.3098e+03, 9.4854e+02, 1.3596e+03, 1.0492e+03, 7.7155e-01, 3.9000e+01]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1334.7328,  998.8505,   49.8030,  100.6226]])\n",
      "xywhn: tensor([[0.9534, 0.9513, 0.0356, 0.0958]])\n",
      "xyxy: tensor([[1309.8313,  948.5392, 1359.6343, 1049.1617]])\n",
      "xyxyn: tensor([[0.9356, 0.9034, 0.9712, 0.9992]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([56.])\n",
      "conf: tensor([0.6996])\n",
      "data: tensor([[1.2084e+03, 9.4192e+02, 1.3973e+03, 1.0494e+03, 6.9964e-01, 5.6000e+01]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1302.8506,  995.6546,  188.8668,  107.4745]])\n",
      "xywhn: tensor([[0.9306, 0.9482, 0.1349, 0.1024]])\n",
      "xyxy: tensor([[1208.4172,  941.9174, 1397.2841, 1049.3918]])\n",
      "xyxyn: tensor([[0.8632, 0.8971, 0.9981, 0.9994]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([26.])\n",
      "conf: tensor([0.6060])\n",
      "data: tensor([[5.7832e-01, 7.3749e+02, 2.3674e+02, 9.9638e+02, 6.0598e-01, 2.6000e+01]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[118.6576, 866.9335, 236.1586, 258.8863]])\n",
      "xywhn: tensor([[0.0848, 0.8257, 0.1687, 0.2466]])\n",
      "xyxy: tensor([[5.7832e-01, 7.3749e+02, 2.3674e+02, 9.9638e+02]])\n",
      "xyxyn: tensor([[4.1308e-04, 7.0237e-01, 1.6910e-01, 9.4893e-01]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.5934])\n",
      "data: tensor([[5.9460e+02, 5.4913e+02, 9.9015e+02, 1.0320e+03, 5.9340e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1050, 1400)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[792.3760, 790.5591, 395.5455, 482.8507]])\n",
      "xywhn: tensor([[0.5660, 0.7529, 0.2825, 0.4599]])\n",
      "xyxy: tensor([[ 594.6032,  549.1338,  990.1487, 1031.9845]])\n",
      "xyxyn: tensor([[0.4247, 0.5230, 0.7072, 0.9828]])\n"
     ]
    }
   ],
   "source": [
    "for i in result_info[0].boxes:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 이미지 객체 식별 결과 확인\n",
    "# show_image(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### 커널이 죽는다. 그냥 쓰지 말자.\n",
    "# cv2.imshow(\"Image\", result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text_017_220_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
