{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x1, y1, x2, y2):\n",
    "    return ((x1-x2)**2 + (y1-y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_line(img, forklift_deque, color, thickness):\n",
    "    \"\"\"\n",
    "    forklift 의 최근 n개 프레임 정보를 사용해서 진행 방향을 구하고, 사진 상에서의 양 끝점을 구하는 함수\n",
    "    n개 프레임 정보가 저장된 deque 내의 가장 첫 값과 끝 값을 사용해서 두 점을 잇는 직선을 구한다.\n",
    "    - forklift_deque : forklift의 바운딩 박스 좌표를 저장하는 deque 객체 \n",
    "    \"\"\"\n",
    "    \n",
    "    # deque 내의 값이 충분하지 않을 경우 종료\n",
    "    deque_len = len(forklift_deque)\n",
    "    if deque_len <= 1:\n",
    "        return\n",
    "    \n",
    "    # 대상 사진의 높이, 너비\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    x1, y1, _, _ = forklift_deque[0]\n",
    "    x2, y2, _, _ = forklift_deque[-1]\n",
    "    \n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    grad = dy / dx\n",
    "    \n",
    "    if dx == 0: # 세로선\n",
    "        cv2.line(img, (x1, 0), (x1, height), color, thickness)\n",
    "    elif dy == 0:   # 가로선\n",
    "        cv2.line(img, (0, y1), (width, y1), color, thickness)\n",
    "    else:\n",
    "        points = []\n",
    "        \n",
    "        # left border (x=0)\n",
    "        y = y1 - x1 * grad\n",
    "        if 0 <= y <= height:\n",
    "            points.append((0, int(y)))\n",
    "        \n",
    "        # Right border (x=width)\n",
    "        y = y1 + (width - x1) * grad\n",
    "        if 0 <= y <= height:\n",
    "            points.append((width, int(y)))\n",
    "        \n",
    "        # Top border (y=0)\n",
    "        x = x1 - y1 / grad\n",
    "        if 0 <= x <= width:\n",
    "            points.append((int(x), 0))\n",
    "        \n",
    "        # Bottom border (y=height)\n",
    "        x = x1 + (height - y1) / grad\n",
    "        if 0 <= x <= width:\n",
    "            points.append((int(x), height))\n",
    "        \n",
    "        if len(points) == 2:\n",
    "            cv2.line(img, points[0], points[1], color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_route_wrong(forklift_deque, img_width, img_height):\n",
    "    \"\"\" [오류 있음] 쓰지 말 것 \"\"\"\n",
    "    deque_len = len(forklift_deque)\n",
    "    if deque_len == 0:\n",
    "        return\n",
    "    \n",
    "    x1, y1, _, _ = forklift_deque[0]\n",
    "    x2, y2, _, _ = forklift_deque[-1]\n",
    "    \n",
    "    grad = (y2 - y1) / (x2 - x1)\n",
    "    \n",
    "    x_intercept = x1 - (y1 / grad)\n",
    "    y_intercept = y1 - x1 * grad\n",
    "    \n",
    "    if x_intercept > img_width:\n",
    "        x3, y3 = (img_width, grad * (img_width - x1) + y1)\n",
    "    else:\n",
    "        x3, y3 = (x_intercept, 0)\n",
    "    \n",
    "    if y_intercept > img_height:\n",
    "        x4, y4 = ((img_height - y1) / grad + x1, 0)\n",
    "    else:\n",
    "        x4, y4 = (0, y_intercept)\n",
    "    \n",
    "    return x3, y3, x4, y4   # 사진에서 그려지는 직선의 양 끝점 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_route_coefs(forklift_deque):\n",
    "    \"\"\"\n",
    "    forklift 의 최근 n개 프레임 정보를 사용해서 진행 방향의 음함수 계수를 구하는 함수\n",
    "    deque 내의 가장 첫 값과 끝 값을 사용해서 두 점을 잇는 직선을 구한다. (음함수 식 ax+by+c=0)\n",
    "    - forklift_deque : forklift의 바운딩 박스 좌표를 저장하는 deque 객체\n",
    "    \"\"\"\n",
    "    \n",
    "    # deque 내의 값이 충분하지 않을 경우 종료\n",
    "    deque_len = len(forklift_deque)\n",
    "    if deque_len <= 1:\n",
    "        return\n",
    "    \n",
    "    x1, y1, _, _ = forklift_deque[0]\n",
    "    x2, y2, _, _ = forklift_deque[-1]\n",
    "    \n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    grad = dy / dx\n",
    "    \n",
    "    # 음함수 식 ax+by+c=0\n",
    "    if dx == 0:\n",
    "        a, b, c = 1, 0, -x1\n",
    "    elif dy == 0:\n",
    "        a, b, c = 0, 1, -y1\n",
    "    else:\n",
    "        a, b, c = grad, -1, y1 - (a * x1)\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_danger_between_forklift_and_person(forklift_deque, person_bbox):\n",
    "    \"\"\" [여러 사람을 대상으로 작동할 수 있도록 수정 필요]\n",
    "    forklift의 예상 진행 경로를 계산하고, 어떤 한 사람이 그 경로로부터 충분히 떨어져 있는지 판단하는 함수\n",
    "    - forklift_deque : forklift의 바운딩 박스 좌표 여러 개를 저장하는 deque 객체\n",
    "    - person_bbox : person의 바운딩 박스 좌표를 저장하는 리스트 객체\n",
    "    \"\"\"\n",
    "    \n",
    "    coefs = calculate_route_coefs(forklift_deque)\n",
    "    if not coefs: \n",
    "        return\n",
    "    \n",
    "    a, b, c = coefs\n",
    "    x1, y1, w1, h1 = person_bbox\n",
    "    dist = abs(a * x1 + b * y1 + c) / (a**2 + b**2)**0.5\n",
    "    \n",
    "    _, _, w2, h2 = forklift_deque[-1]\n",
    "    forklift_len = (w2**2 + h2**2)**0.5\n",
    "    person_len = (w1**2 + h2**2)**0.5\n",
    "    \n",
    "    danger_flag = True if (forklift_len + person_len) * 0.5 >= dist else False\n",
    "    return danger_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 모델 불러오기\n",
    "model = YOLO(r'./runs/detect/yolov8n_custom_1280x7204/weights/best.pt')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# GPU 설정 (predict)\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 1080, 29.733460762450886)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비디오 파일 로드\n",
    "video_file = \"./datasets/short.mp4\"\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# 비디오 객체가 열렸는지 확인\n",
    "if not cap.isOpened():\n",
    "    print(\"Video open failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "### 비디오 생성 준비\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 비디오의 너비, 높이, fps\n",
    "w, h, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 프레임 detect 데이터를 저장할 리스트 (테스트용)\n",
    "detect_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 143.8ms\n",
      "Speed: 0.0ms preprocess, 143.8ms inference, 2633.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.4ms\n",
      "Speed: 14.5ms preprocess, 94.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 87.1ms\n",
      "Speed: 0.0ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 124.5ms\n",
      "Speed: 0.0ms preprocess, 124.5ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 135.7ms\n",
      "Speed: 15.8ms preprocess, 135.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 147.6ms\n",
      "Speed: 0.0ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 129.0ms\n",
      "Speed: 0.0ms preprocess, 129.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 142.4ms\n",
      "Speed: 0.0ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 159.8ms\n",
      "Speed: 0.0ms preprocess, 159.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 142.6ms\n",
      "Speed: 0.0ms preprocess, 142.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 138.8ms\n",
      "Speed: 0.8ms preprocess, 138.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 139.7ms\n",
      "Speed: 14.6ms preprocess, 139.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 128.4ms\n",
      "Speed: 17.0ms preprocess, 128.4ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 124.4ms\n",
      "Speed: 0.0ms preprocess, 124.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 127.2ms\n",
      "Speed: 8.9ms preprocess, 127.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 127.6ms\n",
      "Speed: 16.6ms preprocess, 127.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 167.8ms\n",
      "Speed: 4.1ms preprocess, 167.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 134.9ms\n",
      "Speed: 6.0ms preprocess, 134.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 135.5ms\n",
      "Speed: 0.0ms preprocess, 135.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 128.8ms\n",
      "Speed: 15.6ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 116.9ms\n",
      "Speed: 16.7ms preprocess, 116.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 111.3ms\n",
      "Speed: 15.7ms preprocess, 111.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 120.1ms\n",
      "Speed: 8.7ms preprocess, 120.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 124.2ms\n",
      "Speed: 15.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 121.2ms\n",
      "Speed: 15.0ms preprocess, 121.2ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 106.7ms\n",
      "Speed: 0.0ms preprocess, 106.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 120.5ms\n",
      "Speed: 7.4ms preprocess, 120.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 117.4ms\n",
      "Speed: 0.0ms preprocess, 117.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 110.0ms\n",
      "Speed: 0.0ms preprocess, 110.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 116.7ms\n",
      "Speed: 0.0ms preprocess, 116.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 121.9ms\n",
      "Speed: 0.0ms preprocess, 121.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 123.9ms\n",
      "Speed: 9.4ms preprocess, 123.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 118.0ms\n",
      "Speed: 15.6ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 115.3ms\n",
      "Speed: 3.2ms preprocess, 115.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 110.5ms\n",
      "Speed: 14.2ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 116.8ms\n",
      "Speed: 3.2ms preprocess, 116.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.1ms\n",
      "Speed: 0.0ms preprocess, 120.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Forklift, 126.2ms\n",
      "Speed: 0.0ms preprocess, 126.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.8ms\n",
      "Speed: 0.5ms preprocess, 118.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.7ms\n",
      "Speed: 0.0ms preprocess, 119.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 114.5ms\n",
      "Speed: 6.7ms preprocess, 114.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.0ms\n",
      "Speed: 0.0ms preprocess, 118.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.1ms\n",
      "Speed: 2.1ms preprocess, 123.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.8ms\n",
      "Speed: 1.3ms preprocess, 128.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.8ms\n",
      "Speed: 0.0ms preprocess, 163.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# 최근 n개 프레임을 저장할 데크(deque) 객체 생성\n",
    "recent_frames = deque(maxlen=3)\n",
    "\n",
    "# 프레임 간격 설정 (가변적)\n",
    "frame_interval = 5\n",
    "\n",
    "# forklift, person valid flag\n",
    "forklift_valid, person_valid = False, False # 초기값 : False\n",
    "\n",
    "# forklift, person count (일정 프레임 이상 존재할 경우 객체 탐지로 인정)\n",
    "# forklift_cnt, person_cnt = 0, 0   # 아직 threshold 설정 안 함\n",
    "\n",
    "# 1프레임씩 읽으며 위험상황 처리\n",
    "while True:\n",
    "    # 트래킹 중인 지게차가 없다면 데크 초기화\n",
    "    if not forklift_valid:\n",
    "        recent_frames.clear()\n",
    "    \n",
    "    # 비디오에서 현재 프레임의 위치\n",
    "    current_frame_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    \n",
    "    # 카메라의 ret, frame 값 가져오기\n",
    "    # - ret : boolean (success or not)\n",
    "    # - frame : image array vector\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret: \n",
    "        break\n",
    "    \n",
    "    if current_frame_pos % frame_interval == 0:\n",
    "        # YOLOv8 모델 적용\n",
    "        # results[0] : ultralytics.engine.results.Results\n",
    "        results = model.track(frame, conf=0.7)\n",
    "        \n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "        detect_results.append(results[0])\n",
    "        \n",
    "        # 지게차가 있는지 확인\n",
    "        if 2 in results[0].boxes.cls:\n",
    "            forklift_valid = True\n",
    "            idx = results[0].boxes.cls.tolist().index(2)\n",
    "            recent_frames.append(results[0].boxes.xywh.tolist()[idx])\n",
    "        else:\n",
    "            forklift_valid = False\n",
    "        \n",
    "        # 사람이 있는지 확인\n",
    "        if 0 in results[0].boxes.cls:\n",
    "            person_valid = True\n",
    "            idx = results[0].boxes.cls.tolist().index(0)\n",
    "            person_frame = results[0].boxes.xywh.tolist()[idx]\n",
    "            # 지게차 예상 진행 루트와의 직선 거리를 계산해서 위험여부를 알려줌\n",
    "            if detect_danger_between_forklift_and_person(recent_frames, person_frame):\n",
    "                # [위험상황 발생 시각 저장 기능] => 구현 예정\n",
    "                cv2.putText(annotated_frame, 'collision risk occurred', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "                print('collision risk occurred')\n",
    "        else:\n",
    "            person_valid = False\n",
    "        \n",
    "        # 예상 진행 루트 표시 (직선)\n",
    "        if len(recent_frames) >= 2:\n",
    "            x1, y1, _, _ = recent_frames[0]\n",
    "            x2, y2, _, _ = recent_frames[-1]\n",
    "            extend_line(annotated_frame, recent_frames, (0, 0, 255), 5)\n",
    "            # cv2.line(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 10)\n",
    "            dist = euclidean_dist(x1, y1, x2, y2)\n",
    "            cv2.putText(annotated_frame, f'Dist : {dist}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "        \n",
    "        # 이미지 크기 조정\n",
    "        scale_factor = 0.5\n",
    "        resized_frame = cv2.resize(annotated_frame, None, fx=scale_factor, fy=scale_factor)\n",
    "        \n",
    "        # 어노테이션된 프레임을 표시\n",
    "        cv2.imshow('RESULT IMAGE', resized_frame)\n",
    "    \n",
    "    # 'q'가 눌리면 루프를 중단\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 비디오 캡처 객체를 해제하고 표시 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detect_results), len(recent_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[938.2415771484375, 266.6779479980469, 554.625, 533.3558959960938]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_frames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[610.776611328125, 150.93067932128906, 411.310791015625, 301.8613586425781]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xywh.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_attributes_info(obj):\n",
    "    \"\"\" 객체가 갖고 있는 속성들의 종류를 리스트로 반환하는 함수 \"\"\"\n",
    "    if obj is None: return\n",
    "\n",
    "    return [attr for attr, value in inspect.getmembers(obj)\n",
    "            if not callable(value) and not attr.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_keys\n",
      "boxes\n",
      "keypoints\n",
      "masks\n",
      "names\n",
      "obb\n",
      "orig_img\n",
      "orig_shape\n",
      "path\n",
      "probs\n",
      "save_dir\n",
      "speed\n"
     ]
    }
   ],
   "source": [
    "### ultralytics.engine.results.Results 속성들\n",
    "temp = get_attributes_info(results[0])\n",
    "for t in temp:\n",
    "    print(t)\n",
    "\n",
    "# https://docs.ultralytics.com/reference/engine/results/#ultralytics.engine.results.BaseTensor.__len__\n",
    "# - boxes : Object containing detection bounding boxes.\n",
    "# - names : Dictionary of class names.\n",
    "# - orig_img : Original image as a numpy array.\n",
    "# - orig_shape : Original image shape in (height, width) format.\n",
    "# - speed : Dictionary of preprocess, inference, and postprocess speeds (ms/image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls\n",
      "conf\n",
      "data\n",
      "id\n",
      "is_track\n",
      "orig_shape\n",
      "shape\n",
      "xywh\n",
      "xywhn\n",
      "xyxy\n",
      "xyxyn\n"
     ]
    }
   ],
   "source": [
    "### ultralytics.engine.results.Boxes 속성들\n",
    "temp = get_attributes_info(results[0].boxes)\n",
    "for t in temp:\n",
    "    print(t)\n",
    "\n",
    "# https://docs.ultralytics.com/reference/engine/results/#ultralytics.engine.results.Results.summary\n",
    "# - cls : the class values of the boxes.\n",
    "# - conf : the confidence values of the boxes.\n",
    "# - data : the raw tensor containing detection boxes and their associated data.\n",
    "# - id : the track IDs of the boxes (if available).\n",
    "# - is_track : \tIndicates whether tracking IDs are included in the box data.\n",
    "# - orig_shape : The original image size as a tuple (height, width), used for normalization.\n",
    "# - xywh : the boxes in xywh format.\n",
    "# - xywhn : the boxes in xywh format normalized by original image size.\n",
    "# - xyxy : the boxes in xyxy format.\n",
    "# - xyxyn : the boxes in xyxy format normalized by original image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1107.2329,  278.1606,  590.8399,  552.2476]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_results[27].boxes.xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_results[27].boxes.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 Persons, 1 Forklift, 88.5ms\n",
      "Speed: 4.0ms preprocess, 88.5ms inference, 1578.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "### 사진 파일 로드\n",
    "# img_file = \"./datasets/multiple_classes.jpg\"\n",
    "# img = cv2.imread(img_file)\n",
    "\n",
    "### 사진 예측\n",
    "# results = model.predict(img, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 54.4ms\n",
      "video 1/1 (frame 2/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.9ms\n",
      "video 1/1 (frame 3/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 52.6ms\n",
      "video 1/1 (frame 4/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 61.4ms\n",
      "video 1/1 (frame 5/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.6ms\n",
      "video 1/1 (frame 6/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 62.1ms\n",
      "video 1/1 (frame 7/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 57.0ms\n",
      "video 1/1 (frame 8/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 60.2ms\n",
      "video 1/1 (frame 9/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 59.6ms\n",
      "video 1/1 (frame 10/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 54.6ms\n",
      "video 1/1 (frame 11/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 54.1ms\n",
      "video 1/1 (frame 12/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 54.7ms\n",
      "video 1/1 (frame 13/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.1ms\n",
      "video 1/1 (frame 14/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 74.1ms\n",
      "video 1/1 (frame 15/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.7ms\n",
      "video 1/1 (frame 16/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 56.7ms\n",
      "video 1/1 (frame 17/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 56.2ms\n",
      "video 1/1 (frame 18/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 19/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 70.7ms\n",
      "video 1/1 (frame 20/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 56.6ms\n",
      "video 1/1 (frame 21/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 73.2ms\n",
      "video 1/1 (frame 22/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 23/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.2ms\n",
      "video 1/1 (frame 24/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 60.3ms\n",
      "video 1/1 (frame 25/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 26/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 27/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 53.3ms\n",
      "video 1/1 (frame 28/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.2ms\n",
      "video 1/1 (frame 29/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 56.5ms\n",
      "video 1/1 (frame 30/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.0ms\n",
      "video 1/1 (frame 31/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.2ms\n",
      "video 1/1 (frame 32/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 33/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 34/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 35/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 65.1ms\n",
      "video 1/1 (frame 36/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 37/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 52.8ms\n",
      "video 1/1 (frame 38/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.0ms\n",
      "video 1/1 (frame 39/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.8ms\n",
      "video 1/1 (frame 40/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 47.5ms\n",
      "video 1/1 (frame 41/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 42/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 52.8ms\n",
      "video 1/1 (frame 43/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.2ms\n",
      "video 1/1 (frame 44/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 45/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 47.7ms\n",
      "video 1/1 (frame 46/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 47/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 48/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 69.6ms\n",
      "video 1/1 (frame 49/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 51.2ms\n",
      "video 1/1 (frame 50/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 64.3ms\n",
      "video 1/1 (frame 51/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 48.7ms\n",
      "video 1/1 (frame 52/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 53/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 66.8ms\n",
      "video 1/1 (frame 54/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.2ms\n",
      "video 1/1 (frame 55/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.2ms\n",
      "video 1/1 (frame 56/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 63.9ms\n",
      "video 1/1 (frame 57/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 58/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 59/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 57.6ms\n",
      "video 1/1 (frame 60/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 62.2ms\n",
      "video 1/1 (frame 61/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 64.4ms\n",
      "video 1/1 (frame 62/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 68.3ms\n",
      "video 1/1 (frame 63/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 47.4ms\n",
      "video 1/1 (frame 64/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 65/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.5ms\n",
      "video 1/1 (frame 66/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.7ms\n",
      "video 1/1 (frame 67/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 58.1ms\n",
      "video 1/1 (frame 68/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.2ms\n",
      "video 1/1 (frame 69/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 70/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.7ms\n",
      "video 1/1 (frame 71/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 53.1ms\n",
      "video 1/1 (frame 72/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 69.8ms\n",
      "video 1/1 (frame 73/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.2ms\n",
      "video 1/1 (frame 74/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.2ms\n",
      "video 1/1 (frame 75/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 64.2ms\n",
      "video 1/1 (frame 76/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 64.3ms\n",
      "video 1/1 (frame 77/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.3ms\n",
      "video 1/1 (frame 78/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.6ms\n",
      "video 1/1 (frame 79/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 80/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 53.1ms\n",
      "video 1/1 (frame 81/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 69.3ms\n",
      "video 1/1 (frame 82/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 50.3ms\n",
      "video 1/1 (frame 83/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 58.8ms\n",
      "video 1/1 (frame 84/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 108.8ms\n",
      "video 1/1 (frame 85/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.4ms\n",
      "video 1/1 (frame 86/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 67.4ms\n",
      "video 1/1 (frame 87/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 58.7ms\n",
      "video 1/1 (frame 88/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 89/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 64.1ms\n",
      "video 1/1 (frame 90/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.7ms\n",
      "video 1/1 (frame 91/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.9ms\n",
      "video 1/1 (frame 92/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 63.4ms\n",
      "video 1/1 (frame 93/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.2ms\n",
      "video 1/1 (frame 94/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.9ms\n",
      "video 1/1 (frame 95/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.7ms\n",
      "video 1/1 (frame 96/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 68.5ms\n",
      "video 1/1 (frame 97/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.1ms\n",
      "video 1/1 (frame 98/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.9ms\n",
      "video 1/1 (frame 99/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 66.8ms\n",
      "video 1/1 (frame 100/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 101/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 49.1ms\n",
      "video 1/1 (frame 102/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 61.5ms\n",
      "video 1/1 (frame 103/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.3ms\n",
      "video 1/1 (frame 104/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 63.9ms\n",
      "video 1/1 (frame 105/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 64.0ms\n",
      "video 1/1 (frame 106/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 63.4ms\n",
      "video 1/1 (frame 107/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 63.9ms\n",
      "video 1/1 (frame 108/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 66.8ms\n",
      "video 1/1 (frame 109/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 66.8ms\n",
      "video 1/1 (frame 110/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 67.6ms\n",
      "video 1/1 (frame 111/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 64.3ms\n",
      "video 1/1 (frame 112/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 67.0ms\n",
      "video 1/1 (frame 113/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 47.4ms\n",
      "video 1/1 (frame 114/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.6ms\n",
      "video 1/1 (frame 115/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 53.2ms\n",
      "video 1/1 (frame 116/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 83.9ms\n",
      "video 1/1 (frame 117/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 63.0ms\n",
      "video 1/1 (frame 118/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 77.3ms\n",
      "video 1/1 (frame 119/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 120/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.7ms\n",
      "video 1/1 (frame 121/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 122/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 60.7ms\n",
      "video 1/1 (frame 123/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 2 Forklift(D)s, 66.8ms\n",
      "video 1/1 (frame 124/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 63.4ms\n",
      "video 1/1 (frame 125/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.6ms\n",
      "video 1/1 (frame 126/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 127/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 128/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.7ms\n",
      "video 1/1 (frame 129/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 130/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 60.8ms\n",
      "video 1/1 (frame 131/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 62.2ms\n",
      "video 1/1 (frame 132/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 77.4ms\n",
      "video 1/1 (frame 133/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 69.7ms\n",
      "video 1/1 (frame 134/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 135/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 136/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 137/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.3ms\n",
      "video 1/1 (frame 138/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 60.6ms\n",
      "video 1/1 (frame 139/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 77.1ms\n",
      "video 1/1 (frame 140/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 141/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.0ms\n",
      "video 1/1 (frame 142/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.3ms\n",
      "video 1/1 (frame 143/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 144/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 145/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 146/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 147/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 148/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.3ms\n",
      "video 1/1 (frame 149/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.8ms\n",
      "video 1/1 (frame 150/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.7ms\n",
      "video 1/1 (frame 151/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.8ms\n",
      "video 1/1 (frame 152/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.3ms\n",
      "video 1/1 (frame 153/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 154/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.9ms\n",
      "video 1/1 (frame 155/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Person, 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 156/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.9ms\n",
      "video 1/1 (frame 157/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 66.8ms\n",
      "video 1/1 (frame 158/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Person, 61.2ms\n",
      "video 1/1 (frame 159/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 61.6ms\n",
      "video 1/1 (frame 160/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 50.1ms\n",
      "video 1/1 (frame 161/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Person, 1 Forklift(D), 83.5ms\n",
      "video 1/1 (frame 162/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 163/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 70.8ms\n",
      "video 1/1 (frame 164/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.1ms\n",
      "video 1/1 (frame 165/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 64.0ms\n",
      "video 1/1 (frame 166/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 167/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.6ms\n",
      "video 1/1 (frame 168/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 84.8ms\n",
      "video 1/1 (frame 169/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 170/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 171/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.5ms\n",
      "video 1/1 (frame 172/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 173/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.7ms\n",
      "video 1/1 (frame 174/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 62.4ms\n",
      "video 1/1 (frame 175/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 73.1ms\n",
      "video 1/1 (frame 176/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 57.1ms\n",
      "video 1/1 (frame 177/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 178/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 84.9ms\n",
      "video 1/1 (frame 179/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Forklift(D), 62.7ms\n",
      "video 1/1 (frame 180/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 84.2ms\n",
      "video 1/1 (frame 181/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.0ms\n",
      "video 1/1 (frame 182/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.7ms\n",
      "video 1/1 (frame 183/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 69.8ms\n",
      "video 1/1 (frame 184/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 76.3ms\n",
      "video 1/1 (frame 185/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 1 Person, 65.7ms\n",
      "video 1/1 (frame 186/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 53.6ms\n",
      "video 1/1 (frame 187/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.4ms\n",
      "video 1/1 (frame 188/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 60.0ms\n",
      "video 1/1 (frame 189/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 58.7ms\n",
      "video 1/1 (frame 190/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.2ms\n",
      "video 1/1 (frame 191/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 71.0ms\n",
      "video 1/1 (frame 192/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 69.4ms\n",
      "video 1/1 (frame 193/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.1ms\n",
      "video 1/1 (frame 194/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.9ms\n",
      "video 1/1 (frame 195/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 71.6ms\n",
      "video 1/1 (frame 196/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 61.4ms\n",
      "video 1/1 (frame 197/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 64.6ms\n",
      "video 1/1 (frame 198/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.7ms\n",
      "video 1/1 (frame 199/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 62.5ms\n",
      "video 1/1 (frame 200/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 68.7ms\n",
      "video 1/1 (frame 201/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 116.0ms\n",
      "video 1/1 (frame 202/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.7ms\n",
      "video 1/1 (frame 203/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.7ms\n",
      "video 1/1 (frame 204/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 52.1ms\n",
      "video 1/1 (frame 205/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 68.2ms\n",
      "video 1/1 (frame 206/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 69.2ms\n",
      "video 1/1 (frame 207/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 68.8ms\n",
      "video 1/1 (frame 208/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 53.7ms\n",
      "video 1/1 (frame 209/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 55.8ms\n",
      "video 1/1 (frame 210/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 62.9ms\n",
      "video 1/1 (frame 211/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.1ms\n",
      "video 1/1 (frame 212/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.0ms\n",
      "video 1/1 (frame 213/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 68.7ms\n",
      "video 1/1 (frame 214/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 49.0ms\n",
      "video 1/1 (frame 215/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.7ms\n",
      "video 1/1 (frame 216/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 63.7ms\n",
      "video 1/1 (frame 217/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 70.3ms\n",
      "video 1/1 (frame 218/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.8ms\n",
      "video 1/1 (frame 219/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 67.0ms\n",
      "video 1/1 (frame 220/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 51.1ms\n",
      "video 1/1 (frame 221/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 82.4ms\n",
      "video 1/1 (frame 222/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.0ms\n",
      "video 1/1 (frame 223/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 50.0ms\n",
      "video 1/1 (frame 224/224) c:\\Users\\kdp\\PycharmProjects\\KDT_MNVISION\\BJY\\yolo\\v9\\datasets\\short.mp4: 640x640 (no detections), 66.0ms\n",
      "Speed: 5.2ms preprocess, 62.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### 비디오 예측\n",
    "# video_file = \"./datasets/short.mp4\"\n",
    "# results = model.predict(source= video_file, save=True, conf=0.7, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text_017_220_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
