import sys, time
import numpy as np
import torch
import cv2
from ultralytics import YOLO
from collections import deque

def extend_line(img, forklift_deque, color, thickness):
    """
    forklift ì˜ ìµœê·¼ nê°œ í”„ë ˆì„ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ì§„í–‰ ë°©í–¥ì„ êµ¬í•˜ê³ , ì‚¬ì§„ ìƒì—ì„œì˜ ì–‘ ëì ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜
    nê°œ í”„ë ˆì„ ì •ë³´ê°€ ì €ì¥ëœ deque ë‚´ì˜ ê°€ì¥ ì²« ê°’ê³¼ ë ê°’ì„ ì‚¬ìš©í•´ì„œ ë‘ ì ì„ ì‡ëŠ” ì§ì„ ì„ êµ¬í•œë‹¤.
    - forklift_deque : forkliftì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” deque ê°ì²´ 
    """
    
    # deque ë‚´ì˜ ê°’ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš° ì¢…ë£Œ
    deque_len = len(forklift_deque)
    if deque_len <= 1:
        return
    
    # ëŒ€ìƒ ì‚¬ì§„ì˜ ë†’ì´, ë„ˆë¹„
    height, width, _ = img.shape
    
    x1, y1, _, _ = forklift_deque[0]
    x2, y2, _, _ = forklift_deque[-1]
    
    dx = x2 - x1
    dy = y2 - y1
    grad = dy / dx
    
    if dx == 0: # ì„¸ë¡œì„ 
        cv2.line(img, (x1, 0), (x1, height), color, thickness, cv2.LINE_AA)
    elif dy == 0:   # ê°€ë¡œì„ 
        cv2.line(img, (0, y1), (width, y1), color, thickness, cv2.LINE_AA)
    else:
        points = []
        
        # left border (x=0)
        y = y1 - x1 * grad
        if 0 <= y <= height:
            points.append((0, int(y)))
        
        # Right border (x=width)
        y = y1 + (width - x1) * grad
        if 0 <= y <= height:
            points.append((width, int(y)))
        
        # Top border (y=0)
        x = x1 - y1 / grad
        if 0 <= x <= width:
            points.append((int(x), 0))
        
        # Bottom border (y=height)
        x = x1 + (height - y1) / grad
        if 0 <= x <= width:
            points.append((int(x), height))
        
        if len(points) == 2:
            cv2.line(img, points[0], points[1], color, thickness, cv2.LINE_AA)


def calculate_route_coefs(forklift_deque):
    """
    forklift ì˜ ìµœê·¼ nê°œ í”„ë ˆì„ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ì§„í–‰ ë°©í–¥ì˜ ìŒí•¨ìˆ˜ ê³„ìˆ˜ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜
    deque ë‚´ì˜ ê°€ì¥ ì²« ê°’ê³¼ ë ê°’ì„ ì‚¬ìš©í•´ì„œ ë‘ ì ì„ ì‡ëŠ” ì§ì„ ì„ êµ¬í•œë‹¤. (ìŒí•¨ìˆ˜ ì‹ ax+by+c=0)
    - forklift_deque : forkliftì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” deque ê°ì²´
    """
    
    # deque ë‚´ì˜ ê°’ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš° ì¢…ë£Œ
    deque_len = len(forklift_deque)
    if deque_len <= 1:
        return
    
    x1, y1, _, _ = forklift_deque[0]
    x2, y2, _, _ = forklift_deque[-1]
    
    dx = x2 - x1
    dy = y2 - y1
    grad = dy / dx
    
    # ìŒí•¨ìˆ˜ ì‹ ax+by+c=0
    if dx == 0:
        a, b, c = 1, 0, -x1
    elif dy == 0:
        a, b, c = 0, 1, -y1
    else:
        a, b, c = grad, -1, y1 - (a * x1)
    
    return a, b, c


def detect_danger_between_forklift_and_person(forklift_deque, person_bbox):
    """ [ì—¬ëŸ¬ ì‚¬ëŒì„ ëŒ€ìƒìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì • í•„ìš”]
    forkliftì˜ ì˜ˆìƒ ì§„í–‰ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ê³ , ì–´ë–¤ í•œ ì‚¬ëŒì´ ê·¸ ê²½ë¡œë¡œë¶€í„° ì¶©ë¶„íˆ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
    - forklift_deque : forkliftì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì—¬ëŸ¬ ê°œë¥¼ ì €ì¥í•˜ëŠ” deque ê°ì²´
    - person_bbox : personì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ê°ì²´
    """
    
    coefs = calculate_route_coefs(forklift_deque)
    if not coefs: 
        return
    
    a, b, c = coefs
    x1, y1, w1, h1 = person_bbox
    dist = abs(a * x1 + b * y1 + c) / (a**2 + b**2)**0.5
    
    _, _, w2, h2 = forklift_deque[-1]
    forklift_len = (w2**2 + h2**2)**0.5
    person_len = (w1**2 + h2**2)**0.5
    
    danger_flag = True if (forklift_len + person_len) * 0.5 >= dist else False
    return danger_flag


def detect_danger(cv2_texts, results, forklift_frames, forklift_valid):
    """
    ì‚¬ëŒ-ì§€ê²Œì°¨ ê°„ ìœ„í—˜ìƒí™© ê°ì§€ í•¨ìˆ˜
    - cv2_texts : ìœ„í—˜ìƒí™© ê´€ë ¨ cv2 í‘œì‹œí•  í…ìŠ¤íŠ¸ ì‚¬í•­ ëª¨ìŒ ë¦¬ìŠ¤íŠ¸
    - predict_frame : YOLOv8 ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ë¼ë²¨ë§ ëœ í”„ë ˆì„ (ndarray)
    - forklift_frames : forkliftì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ì €ì¥í•˜ëŠ” deque ê°ì²´ 
    """
    
    # ì§€ê²Œì°¨ê°€ ìˆëŠ”ì§€ í™•ì¸
    if 2 in results[0].boxes.cls:
        forklift_valid = True
        idx = results[0].boxes.cls.tolist().index(2)
        forklift_frames.append(results[0].boxes.xywh.tolist()[idx])
    else:
        forklift_valid = False
    
    # ì‚¬ëŒì´ ìˆëŠ”ì§€ í™•ì¸
    if forklift_valid and (0 in results[0].boxes.cls):
        person_valid = True
        idx = results[0].boxes.cls.tolist().index(0)
        person_frame = results[0].boxes.xywh.tolist()[idx]
        # ì§€ê²Œì°¨ ì˜ˆìƒ ì§„í–‰ ë£¨íŠ¸ì™€ì˜ ì§ì„  ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì„œ ìœ„í—˜ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤Œ
        if detect_danger_between_forklift_and_person(forklift_frames, person_frame):
            # [ìœ„í—˜ìƒí™© ë°œìƒ ì‹œê° ì €ì¥ ê¸°ëŠ¥] => êµ¬í˜„ ì˜ˆì •
            cv2_texts.append(('collision risk detected', (10, 960), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255)))
            # cv2.putText(predict_frame, 'collision risk occurred', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))
            print('collision risk detected')
    else:
        person_valid = False
    
    # # ì˜ˆìƒ ì§„í–‰ ë£¨íŠ¸ í‘œì‹œ (ì§ì„ )
    # if len(forklift_frames) >= 2:
    #     x1, y1, _, _ = forklift_frames[0]
    #     x2, y2, _, _ = forklift_frames[-1]
    #     extend_line(predict_frame, forklift_frames, (0, 255, 0), 3)
    #     # cv2.line(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 10)
    #     dist = ((x1-x2)**2 + (y1-y2)**2)**0.5
    #     cv2_texts.append((f'Dist : {dist:.3f}', (50, 990), cv2.FONT_HERSHEY_TRIPLEX, 1.2, (0, 255, 0)))
    #     # cv2.putText(predict_frame, f'Dist : {dist}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))
    
    return forklift_valid


### ë©”ì¸ ì½”ë“œ

# ì»¤ìŠ¤í…€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = YOLO(r'./runs/detect/yolov8n_custom_1280x7204/weights/best.pt')

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# GPU ì„¤ì • (predict)
# model.to(DEVICE)

# ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
video_file = "./datasets/short.mp4"
cap = cv2.VideoCapture(video_file)

# ë¹„ë””ì˜¤ ê°ì²´ê°€ ì—´ë ¸ëŠ”ì§€ í™•ì¸
if not cap.isOpened():
    print("Video open failed!")
    sys.exit()

# ìµœê·¼ nê°œ í”„ë ˆì„ì„ ì €ì¥í•  ë°í¬(deque) ê°ì²´ ìƒì„±
forklift_frames = deque(maxlen=3)

# í”„ë ˆì„ ê°„ê²© ì„¤ì • (ê°€ë³€ì )
frame_interval = 3

# forklift, person valid flag
forklift_valid, person_valid = False, False # ì´ˆê¸°ê°’ : False

# forklift, person count (ì¼ì • í”„ë ˆì„ ì´ìƒ ì¡´ì¬í•  ê²½ìš° ê°ì²´ íƒì§€ë¡œ ì¸ì •)
# forklift_cnt, person_cnt = 0, 0   # ì•„ì§ threshold ì„¤ì • ì•ˆ í•¨

# 1í”„ë ˆì„ì”© ì½ìœ¼ë©° ìœ„í—˜ìƒí™© ì²˜ë¦¬
while True:
    # ì˜ˆì¸¡ í”„ë ˆì„ì— ì ìš©í•  cv2 ì¶”ê°€ ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
    cv2_labels = []
    
    # íŠ¸ë˜í‚¹ ì¤‘ì¸ ì§€ê²Œì°¨ê°€ ì—†ë‹¤ë©´ ë°í¬ ì´ˆê¸°í™”
    if not forklift_valid: #ğŸ˜
        forklift_frames.clear() #ğŸ˜
    
    # ë¹„ë””ì˜¤ì—ì„œ í˜„ì¬ í”„ë ˆì„ì˜ ìœ„ì¹˜
    current_frame_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
    
    # ì¹´ë©”ë¼ì˜ ret, frame ê°’ ê°€ì ¸ì˜¤ê¸°
    # - ret : boolean (success or not)
    # - frame : image array vector
    ret, frame = cap.read()
    
    if not ret: 
        break
    
    ############################
    # yimsoyoung í˜¸ì¶œ ì½”ë“œ ìœ„ì¹˜ #
    ############################
    
    if current_frame_pos % frame_interval == 0: 
        # YOLOv8 ëª¨ë¸ ì ìš©
        # results[0] : ultralytics.engine.results.Results
        results = model.predict(frame, conf=0.7)
        
        # Visualize the results on the frame
        predict_frame = results[0].plot()
        print(predict_frame)
        
        # ì‚¬ëŒ-ì§€ê²Œì°¨ ê°„ ìœ„í—˜ê°ì§€ ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ 
        forklift_valid = detect_danger(cv2_labels, results, forklift_frames, forklift_valid) #ğŸ˜
    
    # ì–´ë…¸í…Œì´ì…˜ ì‚¬í•­ ì ìš© #ğŸ˜
    for txt, loc, font_type, font_scale, color in cv2_labels:
        cv2.putText(predict_frame, txt, loc, font_type, font_scale, color)
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    scale_factor = 0.5
    resized_frame = cv2.resize(predict_frame, None, fx=scale_factor, fy=scale_factor)
    
    # ì–´ë…¸í…Œì´ì…˜ëœ í”„ë ˆì„ì„ í‘œì‹œ
    cv2.imshow('RESULT IMAGE', resized_frame)
    
    # 'q'ê°€ ëˆŒë¦¬ë©´ ë£¨í”„ë¥¼ ì¤‘ë‹¨
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ë¥¼ í•´ì œí•˜ê³  í‘œì‹œ ì°½ ë‹«ê¸°
cap.release()
cv2.destroyAllWindows()
